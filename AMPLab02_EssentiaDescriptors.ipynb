{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_DLR04ly-fw"
      },
      "source": [
        "# Issues:\n",
        "- AudioDescriptors class takes ~20 hours to compute\n",
        "- AudioDescriptorsExtended a bit less but still too long"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiCspQ4vb-zL",
        "outputId": "5f9997e3-8f36-4d92-a98f-c477a36e8abb"
      },
      "outputs": [],
      "source": [
        "!pip install essentia-tensorflow\n",
        "!pip install numpy pandas scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiHWxgNNa8ga",
        "outputId": "5b928946-7431-4f32-87ad-ce6da504bbc6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SAL51SNcZl0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "import essentia.standard as es\n",
        "import pandas as pd\n",
        "\n",
        "import IPython.display as ipd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from itertools import chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8Z08XBRGEIiS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34maudio.000\u001b[m\u001b[m \u001b[34maudio.001\u001b[m\u001b[m \u001b[34maudio.002\u001b[m\u001b[m \u001b[34maudio.003\u001b[m\u001b[m \u001b[34maudio.004\u001b[m\u001b[m \u001b[34maudio.005\u001b[m\u001b[m \u001b[34maudio.006\u001b[m\u001b[m\n"
          ]
        }
      ],
      "source": [
        "WORKING_DIR = Path(os.getcwd())\n",
        "MODELS_HOME = Path(os.getcwd(), 'models')\n",
        "DATASET_PATH = Path('/Users/francescopapaleo/GDrive/essentia-playlist/MusAV/audio_chunks/')\n",
        "\n",
        "!cd \"$DATASET_PATH\" && ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtQ6OM-vLvSU",
        "outputId": "b6a1f892-42ce-41f3-a4b5-6e419b7bbe41"
      },
      "outputs": [],
      "source": [
        "! mkdir models\n",
        "! curl -L -o models/voice_instrumental-musicnn-mtt-2.pb \"https://essentia.upf.edu/models/classifiers/voice_instrumental/voice_instrumental-musicnn-mtt-2.pb\"\n",
        "! curl -L -o models/discogs-effnet-bs64-1.pb \"https://essentia.upf.edu/models/music-style-classification/discogs-effnet/discogs-effnet-bs64-1.pb\"\n",
        "! curl -L -o models/msd-musicnn-1.pb \"https://essentia.upf.edu/models/autotagging/msd/msd-musicnn-1.pb\"\n",
        "! curl -L -o models/emomusic-musicnn-msd-2.pb \"https://essentia.upf.edu/models/classification-heads/emomusic/emomusic-musicnn-msd-2.pb\"\n",
        "! curl -L -o models/labels.py \"https://raw.githubusercontent.com/MTG/essentia-replicate-demos/main/effnet-discogs/labels.py\"\n",
        "\n",
        "!ls models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "HfuFC1J7B0dm"
      },
      "outputs": [],
      "source": [
        "# function to get a list of all audio files to be analysed under a folder \n",
        "\n",
        "def file_walker(dir_to_analyse, list_type):\n",
        "\n",
        "    def get_files_abspath(dir_to_analyse):\n",
        "        names_abs_list = []\n",
        "        for (dirpath, dirnames, filenames) in os.walk(dir_to_analyse):\n",
        "            for f in filenames:\n",
        "                tmp_abs_path = os.path.join(dirpath, f)\n",
        "                print(tmp_abs_path)\n",
        "                names_abs_list.append(tmp_abs_path)\n",
        "        return names_abs_list\n",
        "\n",
        "    def get_files_relpath(dir_to_analyse):\n",
        "        names_rel_list = []\n",
        "        for (dirpath, dirnames, filenames) in os.walk(dir_to_analyse):\n",
        "            for f in filenames:\n",
        "                tmp_rel_path = os.path.relpath(dirpath, dir_to_analyse)\n",
        "                tmp_file_path = os.path.join(tmp_rel_path, f)\n",
        "                names_rel_list.append(tmp_file_path)\n",
        "        return names_rel_list\n",
        "\n",
        "    def names_only(dir_to_analyse):\n",
        "        names_list = []\n",
        "        for (dirpath, dirnames, filenames) in os.walk(dir_to_analyse):\n",
        "            for f in filenames:\n",
        "                names_list.append(f)\n",
        "        return names_list\n",
        "\n",
        "    if list_type == 'abs':\n",
        "        return get_files_abspath(dir_to_analyse)\n",
        "    elif list_type == 'rel':\n",
        "        return get_files_relpath(dir_to_analyse)\n",
        "    elif list_type == 'names':\n",
        "        return names_only(dir_to_analyse)\n",
        "    else:\n",
        "        print('Error: list_type must be either \"abs\" or \"rel\" or \"names\"')\n",
        "        return None\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRNeph6lBn3E"
      },
      "outputs": [],
      "source": [
        "# Check if the files are already listed, if not calling the function\n",
        "\n",
        "if not os.path.exists('data/all_files_list.json'):\n",
        "    print('Listing all files in the', DATASET_PATH)\n",
        "    with open('data/all_files_list.json', 'w') as f:\n",
        "        all_files_list = []\n",
        "        all_files_list = file_walker(DATASET_PATH, 'abs')\n",
        "        json.dump(all_files_list, f)\n",
        "    print(\"File list saved to all_files_list.json\")\n",
        "    print(\"The list contains\", len(all_files_list), \"files\")\n",
        "else:\n",
        "    print(\"File list exists, you can run one of the descriptors clases\")\n",
        "    with open('data/all_files_list.json', 'r') as f:\n",
        "        all_files_list = json.load(f)\n",
        "    print(\"The list contains\", len(all_files_list), \"files\")\n",
        "if len(all_files_list) == 0:\n",
        "    print(\"No audio files found in the specified directory and its subdirectories, please check the path and try again\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jf2Hc2s10QA7"
      },
      "outputs": [],
      "source": [
        "### CLASS to compute audio descriptors WITH STYLE ACTIVATIONS for 400 STYLES ### \n",
        "\n",
        "# voice_instrumental-msd-musicnn-1.pb\n",
        "\n",
        "class AudioDescriptorsExtended:\n",
        "    def __init__(self):\n",
        "        self.model_effnet = es.TensorflowPredictEffnetDiscogs(graphFilename='/Users/francescopapaleo/Dropbox/Mac/Documents/git-box/streamlit/models/discogs-effnet-bs64-1.pb')\n",
        "        self.model_vi = es.TensorflowPredictMusiCNN(graphFilename='/Users/francescopapaleo/Dropbox/Mac/Documents/git-box/streamlit/models/voice_instrumental-musicnn-mtt-2.pb', output='model/dense/BiasAdd')\n",
        "        self.model_av_emb = es.TensorflowPredictMusiCNN(graphFilename=\"/Users/francescopapaleo/Dropbox/Mac/Documents/git-box/streamlit/models/msd-musicnn-1.pb\", output='model/dense/BiasAdd')\n",
        "        self.model_av = es.TensorflowPredict2D(graphFilename='/Users/francescopapaleo/Dropbox/Mac/Documents/git-box/streamlit/models/emomusic-musicnn-msd-2.pb', output='model/Identity')\n",
        "\n",
        "    def tempo_dance(self, path_to_file):\n",
        "        audio = es.MonoLoader(filename=path_to_file, sampleRate=44100)()\n",
        "        bpm, beats, beats_confidence, _, beats_intervals = es.RhythmExtractor2013()(audio)\n",
        "        danceability, dfa = es.Danceability()(audio)\n",
        "        return bpm, danceability\n",
        "\n",
        "    def audio_16(self, path_to_file):\n",
        "        audio_load_16 = es.MonoLoader(filename=path_to_file, sampleRate=16000)()\n",
        "        return audio_load_16\n",
        "\n",
        "    def style_ml(self, audio_load_16):\n",
        "        activations = self.model_effnet(audio_load_16)\n",
        "        activations_mean = np.mean(activations, axis=0)\n",
        "        activations_list = list(activations_mean.astype(float))\n",
        "        return activations_list\n",
        "\n",
        "\n",
        "    def vi_ml(self, audio_load_16):\n",
        "        activations = self.model_vi(audio_load_16)\n",
        "        v_i_mean = np.mean(activations, axis=0, keepdims=True)[0]\n",
        "        vi_tmp = (v_i_mean + 1) / 2  # Scale to range [0, 1]\n",
        "        vi_scaled = vi_tmp.tolist()\n",
        "        return vi_scaled\n",
        "\n",
        "    def av_ml(self, audio_load_16):\n",
        "        embeddings = self.model_av_emb(audio_load_16)\n",
        "        activations = self.model_av(embeddings)\n",
        "        activations_mean = np.mean(activations, axis=0, keepdims=True)[0]\n",
        "        valence = activations_mean[0]\n",
        "        arousal = activations_mean[1]\n",
        "        return valence, arousal\n",
        "\n",
        "    def compute_descriptors(self, files_list):\n",
        "        all_descriptors = []\n",
        "        for file_path in files_list:\n",
        "            rel_path = os.path.relpath(file_path)\n",
        "            audio_16 = self.audio_16(file_path)\n",
        "            activations_list = self.style_ml(audio_16)\n",
        "            vi_scaled = self.vi_ml(audio_16)\n",
        "            valence, arousal = self.av_ml(audio_16)\n",
        "            bpm, danceability = self.tempo_dance(file_path)\n",
        "\n",
        "            descriptor_dict = {\n",
        "                'file_path': rel_path,\n",
        "                'bpm': str(bpm),\n",
        "                'danceability': str(danceability),\n",
        "                'style_activations': str(activations_list),\n",
        "                'vi_scaled': str(vi_scaled),\n",
        "                'valence': str(valence),\n",
        "                'arousal': str(arousal)\n",
        "            }\n",
        "            all_descriptors.append(descriptor_dict)\n",
        "\n",
        "        return all_descriptors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "APs_EJjyG6vV",
        "outputId": "a1361437-54d5-4d1f-a5c8-207bdefc0e9a"
      },
      "outputs": [],
      "source": [
        "extended_descriptors = AudioDescriptorsExtended()\n",
        "\n",
        "with open(\"extended_descriptors_output.json\", \"w\") as f:\n",
        "    for file_path in tqdm(all_files_list):\n",
        "        features = extended_descriptors.compute_descriptors([file_path])\n",
        "        json.dump(features, f, indent=1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "tensorflow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "934776262cbea400f885b802e42a7264402ef1b03f3ceb2b479919474713150c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
