{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_DLR04ly-fw"
      },
      "source": [
        "# Issues:\n",
        "- AudioDescriptors class takes ~20 hours to compute\n",
        "- AudioDescriptorsExtended a bit less but still too long"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiCspQ4vb-zL",
        "outputId": "5f9997e3-8f36-4d92-a98f-c477a36e8abb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: essentia-tensorflow in /Users/francescopapaleo/tensorflow/lib/python3.10/site-packages (2.1b6.dev871)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /Users/francescopapaleo/tensorflow/lib/python3.10/site-packages (from essentia-tensorflow) (1.24.2)\n",
            "Requirement already satisfied: six in /Users/francescopapaleo/tensorflow/lib/python3.10/site-packages (from essentia-tensorflow) (1.16.0)\n",
            "Requirement already satisfied: pyyaml in /Users/francescopapaleo/tensorflow/lib/python3.10/site-packages (from essentia-tensorflow) (6.0)\n",
            "Requirement already satisfied: numpy in /Users/francescopapaleo/tensorflow/lib/python3.10/site-packages (1.24.2)\n",
            "Requirement already satisfied: pandas in /Users/francescopapaleo/tensorflow/lib/python3.10/site-packages (1.5.3)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.2.1-cp310-cp310-macosx_10_9_x86_64.whl (9.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /Users/francescopapaleo/tensorflow/lib/python3.10/site-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/francescopapaleo/tensorflow/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting joblib>=1.1.1\n",
            "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /Users/francescopapaleo/tensorflow/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: six>=1.5 in /Users/francescopapaleo/tensorflow/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
            "Successfully installed joblib-1.2.0 scikit-learn-1.2.1 threadpoolctl-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install essentia-tensorflow\n",
        "!pip install numpy pandas scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiHWxgNNa8ga",
        "outputId": "5b928946-7431-4f32-87ad-ce6da504bbc6"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/gdrive\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m auth\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1SAL51SNcZl0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-21 07:57:59.109284: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "import essentia.standard as es\n",
        "import pandas as pd\n",
        "\n",
        "import IPython.display as ipd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from itertools import chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "8Z08XBRGEIiS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34maudio.000\u001b[m\u001b[m \u001b[34maudio.001\u001b[m\u001b[m \u001b[34maudio.002\u001b[m\u001b[m \u001b[34maudio.003\u001b[m\u001b[m \u001b[34maudio.004\u001b[m\u001b[m \u001b[34maudio.005\u001b[m\u001b[m \u001b[34maudio.006\u001b[m\u001b[m\n"
          ]
        }
      ],
      "source": [
        "WORKING_DIR = Path(os.getcwd())\n",
        "MODELS_HOME = Path(os.getcwd(), 'models')\n",
        "DATASET_PATH = Path('/Users/francescopapaleo/GDrive/essentia-playlist/MusAV/audio_chunks/')\n",
        "\n",
        "!cd \"$DATASET_PATH\" && ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtQ6OM-vLvSU",
        "outputId": "b6a1f892-42ce-41f3-a4b5-6e419b7bbe41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: models: File exists\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 3163k  100 3163k    0     0  3387k      0 --:--:-- --:--:-- --:--:-- 3383k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 17.5M  100 17.5M    0     0  4937k      0  0:00:03  0:00:02  0:00:01 5345k     0  0:00:03  0:00:03 --:--:-- 4937k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 3123k  100 3123k    0     0  2570k      0  0:00:01  0:00:01 --:--:-- 2570k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 82460  100 82460    0     0   619k      0 --:--:-- --:--:-- --:--:--  619k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 11184  100 11184    0     0  37033      0 --:--:-- --:--:-- --:--:-- 37033\n"
          ]
        }
      ],
      "source": [
        "! mkdir models\n",
        "! curl -L -o models/voice_instrumental-musicnn-mtt-2.pb \"https://essentia.upf.edu/models/classifiers/voice_instrumental/voice_instrumental-musicnn-mtt-2.pb\"\n",
        "! curl -L -o models/discogs-effnet-bs64-1.pb \"https://essentia.upf.edu/models/music-style-classification/discogs-effnet/discogs-effnet-bs64-1.pb\"\n",
        "! curl -L -o models/msd-musicnn-1.pb \"https://essentia.upf.edu/models/autotagging/msd/msd-musicnn-1.pb\"\n",
        "! curl -L -o models/emomusic-musicnn-msd-2.pb \"https://essentia.upf.edu/models/classification-heads/emomusic/emomusic-musicnn-msd-2.pb\"\n",
        "! curl -L -o models/labels.py \"https://raw.githubusercontent.com/MTG/essentia-replicate-demos/main/effnet-discogs/labels.py\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "HfuFC1J7B0dm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1944\n"
          ]
        }
      ],
      "source": [
        "# function to get a list of all audio files to be analysed under a folder \n",
        "\n",
        "def get_all_files(dir_to_analyse):\n",
        "    names_rel_list = []\n",
        "    for (dirpath, dirnames, filenames) in os.walk(dir_to_analyse):\n",
        "        for f in filenames:\n",
        "            tmp_rel_path = os.path.relpath(dirpath, dir_to_analyse)\n",
        "            tmp_file_path = os.path.join(tmp_rel_path, f)\n",
        "            names_rel_list.append(tmp_file_path)\n",
        "    return names_rel_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "VRNeph6lBn3E"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Listing all files in the /Users/francescopapaleo/GDrive/essentia-playlist/MusAV/audio_chunks\n",
            "File list saved to all_files_list.json\n",
            "The list contains 2100 files\n"
          ]
        }
      ],
      "source": [
        "# Check if the files are already listed, if not calling the function\n",
        "\n",
        "if not os.path.exists('data/all_files_list.json'):\n",
        "    print('Listing all files in the', DATASET_PATH)\n",
        "    with open('data/all_files_list.json', 'w') as f:\n",
        "        all_files_list = []\n",
        "        all_files_list = get_all_files(DATASET_PATH)\n",
        "        json.dump(all_files_list, f)\n",
        "    print(\"File list saved to all_files_list.json\")\n",
        "    print(\"The list contains\", len(all_files_list), \"files\")\n",
        "else:\n",
        "    print(\"File list exists, you can run one of the descriptors clases\")\n",
        "    with open('data/all_files_list.json', 'r') as f:\n",
        "        all_files_list = json.load(f)\n",
        "    print(\"The list contains\", len(all_files_list), \"files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Listing all files in the DATASET_PATH...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File list saved to all_files_list.json\n",
            "The list contains 0 files\n",
            "No audio files found in the specified directory and its subdirectories\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(os.path.join(GIT_DATA, \"all_files_list.json\")):\n",
        "    print(\"Listing all files in the DATASET_PATH...\")\n",
        "    with open(GIT_DATA / \"all_files_list.json\", \"w\") as f:\n",
        "        all_files_list = get_all_files(DATASET_PATH)\n",
        "        json.dump(all_files_list, f)\n",
        "    print(\"File list saved to all_files_list.json\")\n",
        "    print(\"The list contains\", len(all_files_list), \"files\")\n",
        "else:\n",
        "    print(\"File list exists, you can run one of the descriptors clases\")\n",
        "    # Load the JSON if already stored\n",
        "    with open(GIT_DATA / \"all_files_list.json\", 'r') as f:\n",
        "        all_files_list = json.load(f)\n",
        "    print(\"The list contains\", len(all_files_list), \"files\")\n",
        "\n",
        "if not all_files_list:\n",
        "    print(\"No audio files found in the specified directory and its subdirectories\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "Te_h3nOPRZbn",
        "outputId": "11587c68-c6de-4640-9a49-e82e40cf06f1"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'AudioDescriptors' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m descriptors \u001b[39m=\u001b[39m AudioDescriptors()\n\u001b[1;32m      3\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mdescriptors_output.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m tqdm(all_files_list):\n",
            "\u001b[0;31mNameError\u001b[0m: name 'AudioDescriptors' is not defined"
          ]
        }
      ],
      "source": [
        "descriptors = AudioDescriptors()\n",
        "\n",
        "with open(\"descriptors_output.json\", \"w\") as f:\n",
        "    for file in tqdm(all_files_list):\n",
        "        descriptors_dict = {}\n",
        "\n",
        "        # Compute the audio features for the current file\n",
        "        audio = descriptors.audio_16(file)\n",
        "        tempo, danceability = descriptors.tempo_dance(file)\n",
        "        style_label = descriptors.style_ml(audio)\n",
        "        vi_label = descriptors.vi_ml(audio)\n",
        "        valence, arousal = descriptors.av_ml(audio)\n",
        "\n",
        "        descriptors_dict['file'] = file\n",
        "        descriptors_dict['tempo'] = float(tempo)\n",
        "        descriptors_dict['danceability'] = float(danceability)\n",
        "        descriptors_dict['valence'] = float(valence)\n",
        "        descriptors_dict['arousal'] = float(arousal)\n",
        "        descriptors_dict['style'] = style_label\n",
        "        descriptors_dict['vi_label'] = vi_label\n",
        "\n",
        "        json.dump(descriptors_dict, f)\n",
        "        f.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jf2Hc2s10QA7"
      },
      "outputs": [],
      "source": [
        "### CLASS to compute audio descriptors WITH STYLE ACTIVATIONS for 400 STYLES ### \n",
        "\n",
        "\n",
        "# voice_instrumental-msd-musicnn-1.pb\n",
        "\n",
        "class AudioDescriptorsExtended:\n",
        "    def __init__(self):\n",
        "        self.model_effnet = es.TensorflowPredictEffnetDiscogs(graphFilename='/Users/francescopapaleo/Dropbox/Mac/Documents/git-box/streamlit/models/discogs-effnet-bs64-1.pb')\n",
        "        self.model_vi = es.TensorflowPredictMusiCNN(graphFilename='/Users/francescopapaleo/Dropbox/Mac/Documents/git-box/streamlit/models/voice_instrumental-musicnn-mtt-2.pb', output='model/dense/BiasAdd')\n",
        "        self.model_av_emb = es.TensorflowPredictMusiCNN(graphFilename=\"/Users/francescopapaleo/Dropbox/Mac/Documents/git-box/streamlit/models/msd-musicnn-1.pb\", output='model/dense/BiasAdd')\n",
        "        self.model_av = es.TensorflowPredict2D(graphFilename='/Users/francescopapaleo/Dropbox/Mac/Documents/git-box/streamlit/models/emomusic-musicnn-msd-2.pb', output='model/Identity')\n",
        "\n",
        "    def tempo_dance(self, path_to_file):\n",
        "        audio = es.MonoLoader(filename=path_to_file, sampleRate=44100)()\n",
        "        bpm, beats, beats_confidence, _, beats_intervals = es.RhythmExtractor2013()(audio)\n",
        "        danceability, dfa = es.Danceability()(audio)\n",
        "        return bpm, danceability\n",
        "\n",
        "    def audio_16(self, path_to_file):\n",
        "        audio_load_16 = es.MonoLoader(filename=path_to_file, sampleRate=16000)()\n",
        "        return audio_load_16\n",
        "\n",
        "    def style_ml(self, audio_load_16):\n",
        "        activations = self.model_effnet(audio_load_16)\n",
        "        activations_mean = np.mean(activations, axis=0)\n",
        "        activations_list = list(activations_mean.astype(float))\n",
        "        return activations_list\n",
        "\n",
        "\n",
        "    def vi_ml(self, audio_load_16):\n",
        "        activations = self.model_vi(audio_load_16)\n",
        "        v_i_mean = np.mean(activations, axis=0, keepdims=True)[0]\n",
        "        vi_tmp = (v_i_mean + 1) / 2  # Scale to range [0, 1]\n",
        "        vi_scaled = vi_tmp.tolist()\n",
        "        return vi_scaled\n",
        "\n",
        "    def av_ml(self, audio_load_16):\n",
        "        embeddings = self.model_av_emb(audio_load_16)\n",
        "        activations = self.model_av(embeddings)\n",
        "        activations_mean = np.mean(activations, axis=0, keepdims=True)[0]\n",
        "        valence = activations_mean[0]\n",
        "        arousal = activations_mean[1]\n",
        "        return valence, arousal\n",
        "\n",
        "    def compute_descriptors(self, files_list):\n",
        "        all_descriptors = []\n",
        "        for file_path in files_list:\n",
        "            rel_path = os.path.relpath(file_path)\n",
        "            audio_16 = self.audio_16(file_path)\n",
        "            activations_list = self.style_ml(audio_16)\n",
        "            vi_scaled = self.vi_ml(audio_16)\n",
        "            valence, arousal = self.av_ml(audio_16)\n",
        "            bpm, danceability = self.tempo_dance(file_path)\n",
        "\n",
        "            descriptor_dict = {\n",
        "                'file_path': rel_path,\n",
        "                'bpm': str(bpm),\n",
        "                'danceability': str(danceability),\n",
        "                'style_activations': str(activations_list),\n",
        "                'vi_scaled': str(vi_scaled),\n",
        "                'valence': str(valence),\n",
        "                'arousal': str(arousal)\n",
        "            }\n",
        "            all_descriptors.append(descriptor_dict)\n",
        "\n",
        "        return all_descriptors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "APs_EJjyG6vV",
        "outputId": "a1361437-54d5-4d1f-a5c8-207bdefc0e9a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/Users/francescopapaleo/Dropbox/Mac/Documents/git-box/streamlit/models/discogs-effnet-bs64-1.pb`\n",
            "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/Users/francescopapaleo/Dropbox/Mac/Documents/git-box/streamlit/models/voice_instrumental-musicnn-mtt-2.pb`\n",
            "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/Users/francescopapaleo/Dropbox/Mac/Documents/git-box/streamlit/models/msd-musicnn-1.pb`\n",
            "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `/Users/francescopapaleo/Dropbox/Mac/Documents/git-box/streamlit/models/emomusic-musicnn-msd-2.pb`\n",
            "  0%|          | 0/2100 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Error while configuring MonoLoader: AudioLoader: Could not open file \"/content/gdrive/MyDrive/AMPLAB/MusAV/audio_chunks/audio.000/1t/1tnci80rcW5LjqQqBwdZsW.mp3\", error = No such file or directory",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mextended_descriptors_output.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     \u001b[39mfor\u001b[39;00m file_path \u001b[39min\u001b[39;00m tqdm(all_files_list):\n\u001b[0;32m----> 5\u001b[0m         features \u001b[39m=\u001b[39m extended_descriptors\u001b[39m.\u001b[39;49mcompute_descriptors([file_path])\n\u001b[1;32m      6\u001b[0m         json\u001b[39m.\u001b[39mdump(features, f, indent\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
            "Cell \u001b[0;32mIn[26], line 49\u001b[0m, in \u001b[0;36mAudioDescriptorsExtended.compute_descriptors\u001b[0;34m(self, files_list)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mfor\u001b[39;00m file_path \u001b[39min\u001b[39;00m files_list:\n\u001b[1;32m     48\u001b[0m     rel_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mrelpath(file_path)\n\u001b[0;32m---> 49\u001b[0m     audio_16 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maudio_16(file_path)\n\u001b[1;32m     50\u001b[0m     activations_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstyle_ml(audio_16)\n\u001b[1;32m     51\u001b[0m     vi_scaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvi_ml(audio_16)\n",
            "Cell \u001b[0;32mIn[26], line 20\u001b[0m, in \u001b[0;36mAudioDescriptorsExtended.audio_16\u001b[0;34m(self, path_to_file)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maudio_16\u001b[39m(\u001b[39mself\u001b[39m, path_to_file):\n\u001b[0;32m---> 20\u001b[0m     audio_load_16 \u001b[39m=\u001b[39m es\u001b[39m.\u001b[39;49mMonoLoader(filename\u001b[39m=\u001b[39;49mpath_to_file, sampleRate\u001b[39m=\u001b[39;49m\u001b[39m16000\u001b[39;49m)()\n\u001b[1;32m     21\u001b[0m     \u001b[39mreturn\u001b[39;00m audio_load_16\n",
            "File \u001b[0;32m~/tensorflow/lib/python3.10/site-packages/essentia/standard.py:44\u001b[0m, in \u001b[0;36m_create_essentia_class.<locals>.Algo.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m _essentia\u001b[39m.\u001b[39mAlgorithm\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name)\n\u001b[1;32m     43\u001b[0m \u001b[39m# configure the algorithm\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfigure(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/tensorflow/lib/python3.10/site-packages/essentia/standard.py:64\u001b[0m, in \u001b[0;36m_create_essentia_class.<locals>.Algo.configure\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError cannot convert parameter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\\\n\u001b[1;32m     60\u001b[0m                         \u001b[39m%\u001b[39m(\u001b[39mstr\u001b[39m(_c\u001b[39m.\u001b[39mdetermineEdt(val)),\u001b[39mstr\u001b[39m(goalType))) \u001b[39m#\\''+name+'\\' parameter: '+str(e))\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     kwargs[name] \u001b[39m=\u001b[39m convertedVal\n\u001b[0;32m---> 64\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__configure__(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error while configuring MonoLoader: AudioLoader: Could not open file \"/content/gdrive/MyDrive/AMPLAB/MusAV/audio_chunks/audio.000/1t/1tnci80rcW5LjqQqBwdZsW.mp3\", error = No such file or directory"
          ]
        }
      ],
      "source": [
        "extended_descriptors = AudioDescriptorsExtended()\n",
        "\n",
        "with open(\"extended_descriptors_output.json\", \"w\") as f:\n",
        "    for file_path in tqdm(all_files_list):\n",
        "        features = extended_descriptors.compute_descriptors([file_path])\n",
        "        json.dump(features, f, indent=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDSZ_VJkYxo1",
        "outputId": "07aac296-03bd-4f8b-db38-00384ba48493"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(all_files_list[\u001b[39m0\u001b[39;49m])\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "print(all_files_list[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "tensorflow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "934776262cbea400f885b802e42a7264402ef1b03f3ceb2b479919474713150c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
